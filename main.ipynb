{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM neural network for time series prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load and plot Tesla stock data from 2010 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.110001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adj Close\n",
       "0  23.889999\n",
       "1  23.830000\n",
       "2  21.959999\n",
       "3  19.200001\n",
       "4  16.110001"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_data = pd.read_csv('TSLA_2010_2020.csv')\n",
    "tesla_data = tesla_data.drop(['Date','Open','High','Low','Close','Volume'],axis = 1)\n",
    "total_days = tesla_data.shape[0]\n",
    "tesla_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(tesla_data, label='Tesla stock value', c = 'b')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a LSTM neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class LSTM_nn which is a neural network with LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_nn(nn.Module):\n",
    "    def __init__(self,input_size, num_layers, hidden_size, seq_length):\n",
    "        super(LSTM_nn, self).__init__()\n",
    "        #Attributes from nn.Module\n",
    "        self.input_size = input_size #input size\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        \n",
    "        #New attributes\n",
    "        self.seq_length = seq_length #sequence length\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, batch_first = True) #lstm\n",
    "        \n",
    "        self.fc =  nn.Linear(hidden_size, 1) #fully connected linear\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, X.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, X.size(0), self.hidden_size)) #internal state\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(X, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        final_state = hn.view(self.num_layers, X.size(0), self.hidden_size)[-1]\n",
    "                \n",
    "        # Propagate input through fully connected linear neuron\n",
    "        out = self.fc(final_state)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def _train(self, num_epochs, learning_rate, criterion, X_train, y_train, X_test, y_test):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate) \n",
    "        t = trange(num_epochs+1)\n",
    "        for epoch in t:\n",
    "            #Pass through the neural network\n",
    "            train_outputs = self.forward(X_train) \n",
    "            test_outputs = self.forward(X_test) \n",
    "\n",
    "            #Reset gradients to zero  \n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            train_loss = criterion(train_outputs, y_train)\n",
    "            test_loss = criterion(test_outputs,y_test)\n",
    "\n",
    "            #Backprogagation step\n",
    "            train_loss.backward()\n",
    "\n",
    "            #Update weights and bias of the network\n",
    "            optimizer.step()\n",
    "\n",
    "            #Print train and test loss\n",
    "            t.set_description(\"Epoch: %d, Train loss: %1.5f, Test loss: %1.5f\" % (epoch, train_loss.item(),test_loss.item()))\n",
    "    \n",
    "    def get_horizon_predictions(self, X_data, y_data, scaler, horizon):\n",
    "        total_days = X_data.shape[0]\n",
    "        predictions = np.ndarray(shape=(total_days-horizon+1,horizon), dtype=float)\n",
    "        for i in range(total_days-horizon+1):\n",
    "            X_temp = X_data[i].unsqueeze(0)\n",
    "            for j in range(horizon):\n",
    "                next_prediction = self(X_temp)\n",
    "                predictions[i,j] = scaler.inverse_transform(next_prediction.detach().numpy()).squeeze()\n",
    "                X_temp_shifted = X_temp[:,1:].reshape((1,self.seq_length-1,self.input_size))\n",
    "                X_temp = torch.cat((X_temp_shifted,next_prediction.unsqueeze(0)),1)\n",
    "        return predictions\n",
    "    \n",
    "    def get_accuracy(self, X_data, y_data, naive_prediction, scaler, last_day):\n",
    "        lstm_prediction = scaler.inverse_transform(self(X_data).detach().numpy())\n",
    "        real_values = scaler.inverse_transform(y_data.numpy())\n",
    "\n",
    "        naive_error = mean_squared_error(real_values[:last_day:1],naive_prediction[:last_day:1])\n",
    "        lstm_error = mean_squared_error(real_values[:last_day:1],lstm_prediction[:last_day:1])\n",
    "\n",
    "        naive_r2 = r2_score(real_values[:last_day:1], naive_prediction[:last_day:1])\n",
    "        lstm_r2 = r2_score(real_values[:last_day:1], lstm_prediction[:last_day:1])\n",
    "\n",
    "        print('Mean squared error up to the ' + str(last_day) + ' day using the naive prediction : ' + str(naive_error))\n",
    "        print('Mean squared error up to the ' + str(last_day) + ' day using the lstm prediction : ' + str(lstm_error))\n",
    "        print('R2 up to the ' + str(last_day) + ' day using the naive prediction : ' + str(naive_r2))\n",
    "        print('R2 up to the ' + str(last_day) + ' day using the lstm prediction : ' + str(lstm_r2))\n",
    "    \n",
    "    def get_accuracy_with_horizon(self, X_data, y_data, naive_prediction_without_horizon, scaler, last_day, horizon):\n",
    "        lstm_prediction = self.get_horizon_predictions(X_data, y_data, scaler, horizon)\n",
    "        total_days = lstm_prediction.shape[0]\n",
    "        real_values_without_horizon = scaler.inverse_transform(y_data.numpy())\n",
    "        real_values = np.ndarray(shape=(total_days,horizon), dtype=float)\n",
    "        naive_prediction = np.ndarray(shape=(total_days,horizon), dtype=float)\n",
    "        for i in range(total_days):\n",
    "            for j in range(horizon):\n",
    "                real_values[i,j] = real_values_without_horizon[i+j]\n",
    "                naive_prediction[i,j] = naive_prediction_without_horizon[i]\n",
    "                \n",
    "        naive_error = mean_squared_error(real_values[:last_day:1].flatten(),naive_prediction[:last_day:1].flatten())\n",
    "        lstm_error = mean_squared_error(real_values[:last_day:1].flatten(),lstm_prediction[:last_day:1].flatten())\n",
    "\n",
    "        naive_r2 = r2_score(real_values[:last_day:1].flatten(), naive_prediction[:last_day:1].flatten())\n",
    "        lstm_r2 = r2_score(real_values[:last_day:1].flatten(), lstm_prediction[:last_day:1].flatten())\n",
    "\n",
    "        print('Mean squared error up to the ' + str(last_day) + ' day using the naive prediction : ' + str(naive_error))\n",
    "        print('Mean squared error up to the ' + str(last_day) + ' day using the lstm prediction : ' + str(lstm_error))\n",
    "        print('R2 up to the ' + str(last_day) + ' day using the naive prediction : ' + str(naive_r2))\n",
    "        print('R2 up to the ' + str(last_day) + ' day using the lstm prediction : ' + str(lstm_r2))\n",
    "        \n",
    "    def plot(self, X_data, y_data, scaler):\n",
    "        lstm_prediction = scaler.inverse_transform(self(X_data).detach().numpy())\n",
    "        real_values = scaler.inverse_transform(y_data.numpy())\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(real_values, label='Actual value', c = 'b')\n",
    "        plt.plot(lstm_prediction, label='LSTM Prediction', c = 'r')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_with_horizon(self, X_data, y_data, scaler, horizon):\n",
    "        colors = ['r','g','k','y']\n",
    "        real_values = scaler.inverse_transform(y_data.numpy())\n",
    "        predictions = self.get_horizon_predictions(X_data, y_data, scaler, horizon)\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(real_values, label='Actual value', c = 'b')\n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.plot(np.arange(i,i+horizon),predictions[i], c = colors[i % len(colors)])\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a sliding windows function that takes the previous days as features and the current day as target. It also computes a moving average to reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(l,average_size):\n",
    "    res = np.zeros(len(l)-average_size+1)\n",
    "    for i in range(len(l)-average_size+1):\n",
    "        res[i] = (sum(l[i:i+average_size])/len(l[i:i+average_size]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length, average_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    data = average(np.array(data).reshape(-1),average_size).reshape(-1,1)\n",
    "    for i in range(len(data)-seq_length):\n",
    "        Xi = data[i:(i+seq_length)]\n",
    "        yi = data[i+seq_length]\n",
    "        X.append(Xi)\n",
    "        y.append(yi)\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a process function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, seq_length,average_size, train_proportion, scaler):\n",
    "    data = np.array(data)\n",
    "    \n",
    "    #Fitting on training data\n",
    "    train_size = int(len(data) * train_proportion)\n",
    "    scaler.fit(data[0:train_size])\n",
    "    \n",
    "    #Transforming all data\n",
    "    data_normalized = scaler.transform(data)\n",
    "    X,y = sliding_windows(data_normalized,seq_length, average_size)\n",
    "    \n",
    "    #Raw Target\n",
    "    y_raw = data_normalized[seq_length-1+average_size:]\n",
    "    y_raw = Variable(torch.Tensor(y_raw))\n",
    "    \n",
    "    #All data\n",
    "    X_data = Variable(torch.Tensor(X))\n",
    "    y_data = Variable(torch.Tensor(y))\n",
    "    \n",
    "    #Training \n",
    "    X_train = Variable(torch.Tensor(X[0:train_size]))\n",
    "    y_train = Variable(torch.Tensor(y[0:train_size]))\n",
    "    \n",
    "    #Testing\n",
    "    X_test = Variable(torch.Tensor(X[train_size:len(X)]))\n",
    "    y_test = Variable(torch.Tensor(y[train_size:len(X)]))\n",
    "\n",
    "    return y_raw, X_data, y_data, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a process function with a difference step to avoid prediction based on autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_diff(data, seq_length, average_size, train_proportion, scaler):\n",
    "    data = np.array(data)\n",
    "    \n",
    "    #Differencing the time series\n",
    "    data_diff = np.diff(data.reshape(data.shape[0])).reshape(-1,1)\n",
    "\n",
    "    #Fitting on training data\n",
    "    train_size = int(len(data_diff) * train_proportion)    \n",
    "    scaler.fit(data_diff[0:train_size])\n",
    "    \n",
    "    #Transforming all data\n",
    "    data_normalized = scaler.transform(data_diff)\n",
    "    X,y = sliding_windows(data_normalized,seq_length,average_size)\n",
    "    \n",
    "    #Raw Target\n",
    "    y_raw = data_normalized[seq_length-1+average_size:]\n",
    "    y_raw = Variable(torch.Tensor(y_raw))\n",
    "    \n",
    "    #All data\n",
    "    X_data = Variable(torch.Tensor(X))\n",
    "    y_data = Variable(torch.Tensor(y))\n",
    "    \n",
    "    #Training \n",
    "    X_train = Variable(torch.Tensor(X[0:train_size]))\n",
    "    y_train = Variable(torch.Tensor(y[0:train_size]))\n",
    "        \n",
    "    #Test\n",
    "    X_test = Variable(torch.Tensor(X[train_size:len(X)]))\n",
    "    y_test = Variable(torch.Tensor(y[train_size:len(X)]))\n",
    "\n",
    "    return y_raw, X_data, y_data, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process our data two times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 15\n",
    "average_size = 7\n",
    "train_proportion = 2/3\n",
    "scaler1 = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler2 = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "y_raw1, X_data1, y_data1, X_train1, y_train1, X_test1, y_test1 = process_data(tesla_data, seq_length, average_size, train_proportion, scaler1)\n",
    "y_raw2, X_data2, y_data2, X_train2, y_train2, X_test2, y_test2 = process_data_diff(tesla_data, seq_length, average_size, train_proportion, scaler2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two recurrent neural network with our LSTM_nn class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model1 = LSTM_nn(input_size = 1, num_layers = 2, hidden_size = 21, seq_length = seq_length)\n",
    "my_model2 = LSTM_nn(input_size = 1, num_layers = 2, hidden_size = 21, seq_length = seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our first model with the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Train loss: 0.00061, Test loss: 0.02408: 100%|██████████| 1001/1001 [01:50<00:00,  9.03it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "my_model1._train(num_epochs, learning_rate, criterion, X_train1, y_train1, X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our second model with the differenciated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Train loss: 0.00090, Test loss: 0.00477: 100%|██████████| 1001/1001 [01:52<00:00,  8.91it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()    \n",
    "my_model2._train(num_epochs, learning_rate, criterion, X_train2, y_train2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to save our models parameters for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath1 = 'lstm1'\n",
    "filepath2 = 'lstm2'\n",
    "torch.save(my_model1.state_dict(), filepath1)\n",
    "torch.save(my_model2.state_dict(), filepath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to load saved parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath1 = 'lstm1'\n",
    "filepath2 = 'lstm2'\n",
    "my_model1.load_state_dict(torch.load(filepath1))\n",
    "my_model2.load_state_dict(torch.load(filepath2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating/Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the accuracy of our predictions with the naive prediction $\\hat{y}(t+1 | t) = y(t)$ by computing a MSE loss and a $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First model accuracy :\n",
      "Mean squared error up to the 2400 day using the naive prediction : 6.5070815\n",
      "Mean squared error up to the 2400 day using the lstm prediction : 151.49716\n",
      "R2 up to the 2400 day using the naive prediction : 0.9995270534913108\n",
      "R2 up to the 2400 day using the lstm prediction : 0.988988911208269\n",
      "\n",
      "\n",
      "Second model accuracy :\n",
      "Mean squared error up to the 2400 day using the naive prediction : 6.509801450485878\n",
      "Mean squared error up to the 2400 day using the lstm prediction : 1.696614\n",
      "R2 up to the 2400 day using the naive prediction : -0.009729191623648159\n",
      "R2 up to the 2400 day using the lstm prediction : 0.7368397911867977\n"
     ]
    }
   ],
   "source": [
    "last_day = 2400\n",
    "print('First model accuracy :')\n",
    "naive_prediction1 = scaler1.inverse_transform(X_data1.numpy()[:,my_model1.seq_length-1])\n",
    "my_model1.get_accuracy(X_data1, y_data1, naive_prediction1, scaler1, last_day)\n",
    "print('\\n')\n",
    "print('Second model accuracy :')\n",
    "naive_prediction2 = np.zeros(y_data2.size(0))\n",
    "my_model2.get_accuracy(X_data2, y_data2, naive_prediction2, scaler2, last_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot our predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model1.plot(X_data1, y_data1, scaler1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model2.plot(X_data2, y_data2, scaler2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "We notice on the MSE that the first model performs poorly as it is worse that the naive prediction. We should not consider the high value of $R^2$ as an evidence of quality of our model. The $R^2$ is high because our time series has a high autocorrelation. On the other hand, the second model (which use the differencing time series) performs well with a $R^2 \\simeq 0.73$ while the naive prediction has a $R^2 \\simeq -0.01$. We note that we applied a moving average step on our data and if we compare our predictions with the raw target values, we get poor results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second model accuracy with the raw data:\n",
      "Mean squared error up to the 2400 day using the naive prediction : 50.411859994744155\n",
      "Mean squared error up to the 2400 day using the lstm prediction : 52.72759\n",
      "R2 up to the 2400 day using the naive prediction : -0.002001292492675555\n",
      "R2 up to the 2400 day using the lstm prediction : -0.048029360825675216\n"
     ]
    }
   ],
   "source": [
    "print('Second model accuracy with the raw data:')\n",
    "naive_prediction2 = np.zeros(y_data2.shape[0])\n",
    "my_model2.get_accuracy(X_data2, y_raw2, naive_prediction2, scaler2, last_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model2.plot(X_data2, y_raw2, scaler2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid-19 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the covid-19 data from France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38866</th>\n",
       "      <td>6989613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38867</th>\n",
       "      <td>6994319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38868</th>\n",
       "      <td>6995628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38869</th>\n",
       "      <td>7002393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38870</th>\n",
       "      <td>7008228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Confirmed\n",
       "38866    6989613\n",
       "38867    6994319\n",
       "38868    6995628\n",
       "38869    7002393\n",
       "38870    7008228"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data = pd.read_csv('covid_data.csv')\n",
    "covid_data = covid_data.loc[covid_data['Country'] == 'France']\n",
    "covid_data = covid_data[['Confirmed']]\n",
    "covid_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(covid_data, label='Covid-19 Confirmed Cases', c = 'b')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 15\n",
    "average_size = 3\n",
    "train_proportion = 2/3\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_raw, X_data, y_data, X_train, y_train, X_test, y_test = process_data_diff(covid_data, seq_length, average_size, train_proportion, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = LSTM_nn(input_size = 1, num_layers = 2, hidden_size = 21, seq_length = seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2000, Train loss: 0.00017, Test loss: 0.09462: 100%|██████████| 2001/2001 [01:06<00:00, 30.23it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "my_model._train(num_epochs, learning_rate, criterion, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath3 = 'lstm3'\n",
    "torch.save(my_model.state_dict(), filepath3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath3 = 'lstm3'\n",
    "my_model.load_state_dict(torch.load(filepath3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy :\n",
      "Mean squared error up to the 599 day using the naive prediction : 356789634.5978947\n",
      "Mean squared error up to the 599 day using the lstm prediction : 57304910.0\n",
      "R2 up to the 599 day using the naive prediction : -0.620719894904505\n",
      "R2 up to the 599 day using the lstm prediction : 0.7396919779425882\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy :')\n",
    "last_day = y_data.shape[0]\n",
    "naive_prediction = np.zeros(y_data.shape[0])\n",
    "my_model.get_accuracy(X_data, y_data, naive_prediction, scaler, last_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.plot(X_data, y_data, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 14\n",
    "my_model.plot_with_horizon(X_data, y_data, scaler, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy with horizon:\n",
      "Mean squared error up to the 599 day using the naive prediction : 364376965.44939274\n",
      "Mean squared error up to the 599 day using the lstm prediction : 120085980.14783725\n",
      "R2 up to the 599 day using the naive prediction : -0.6338948808975922\n",
      "R2 up to the 599 day using the lstm prediction : 0.4615250500559649\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy with horizon:')\n",
    "last_day = y_data.shape[0]\n",
    "horizon = 14\n",
    "naive_prediction_without_horizon = np.zeros(y_data.shape[0])\n",
    "my_model.get_accuracy_with_horizon(X_data, y_data, naive_prediction_without_horizon, scaler, last_day, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
